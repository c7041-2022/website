---
title: "Lab 14 GLM"
---

<br>

<center>![Jellyfish](img/lab14-jelly.png){width="300"}</center>

## 1 Objectives

- Fit generalized linear models with `R`

- Evaluate GLM assumptions

- Evaluate statistical and graphical results for GLM


<br>

[Data for all labs (unzip to your working directory)](data/c7041-lab-data.zip)

[Template script](scripts/template_script.R)

<br>

## 2 Start a script!

For this and every lab or project, begin by:

-   **starting a new script**

-   **create a good header section and table of contents**

-   **save the script file with an informative name**

-   **set your working directory**

Aim to make the script useful as a future reference for doing things in `R` - this will come in handy for projects and assessments!

<br>

## 3 Generalized linear models (important stuff)

In this lab we will fit general linear models to data, implemented in the `R` command `glm()`. 
A generalized linear model is useful when the response variable has a distribution other than the Gaussian distribution (like binary outcomes; like data that are counts of something), and when a transformation of the data is undesirable or impossible. Example situations include binary response data (1 or 0, dead or alive) or data that are counts (number of offspring, leaves, or tattoos). The approach is also useful in the analysis of contingency tables.

<br>

<center>![Song sparrow](img/lab14-sparrow.png){width="300"}</center>


## 4 Example: Natural selection in song sparrows

The song sparrow population on the island of Mandarte has been studied for many years by Jamie Smith, Peter Arcese, and collaborators. The birds were measured and banded and their fates on the island have recorded over many years. Here we will look for evidence of natural selection using the relationship between phenotypes and survival.

The data file `songsparrow.csv` gives survival of young-of-the-year females over their first winter (1=survived, 0=died). The file includes measurements of beak and body dimensions: body mass (g), wing length, tarsus length, beak length, beak depth, beak width (all in mm), year of birth, and survival. These data were analyzed previously in D. Schluter and J. N. M Smith (1986, Evolution 40: 221-231).

<br>

### 4.1 Read and examine the data

<br>

1. Read the data from the file and inspect the first few lines to make sure it was read correctly.

2. We’ll be comparing survival probabilities among different years. To this end, make sure that year is a categorical variable in your data frame.

3. Plot survival against tarsus length of female sparrows. Use a method to reduce the overlap of points (the response variable is 0 or 1) to see the patterns more clearly.

4. Examine the plot. Can you visualize a trend? Use a smoothing method to see if any trend is present (most methods won’t constrain the curve to lie between 0 and 1, but at least you’ll get an idea).

<br>

### 4.2 Fit a generalized linear model

<br>

Let’s start by ignoring the fact that the data are from multiple years. We will have the option later to add year to the model to see if it makes a difference.

5. The response variable is binary. What probability distribution is appropriate to describe the error distribution around a model fit? What is an appropriate link function?

6. Fit a generalized linear model to the data on survival and tarsus length.

7. Use `visreg()` to visualize the model fit.

8. Obtain the estimated regression coefficients for the fitted model. What is the interpretation of these coefficients? On a piece of paper, write down the complete formula for the model shown in the visreg plot.

9. Use the coefficients to calculate the predicted survival probability of a song sparrow having tarsus length 20.5 mm*. Does the result agree with your plot of the fitted regression curve?

10. The ratio (-intercept/slope) estimates the point at which probability of survival is changing most rapidly. In toxicology this point is known as the LD50. Calculate this value** and compare it visually with the fitted curve. Does it agree? Finally, the slope of the curve at a given value for the explanatory variable `x` is `b * p(x) * ( 1 - p(x) )`, where `b` is the slope coefficient of the fitted logistic regression model and `p(x)` is the predicted probability of survival at that x.

11. Calculate the likelihood-based 95% confidence interval for the logistic regression coefficients.

12. The `summary(z)` output for the regression coefficients also includes “z values” and P-values. What caution would you take when interpreting these P-values? Use a more accurate method to test the null hypothesis of zero slope.

\* -1.148577; 0.2407491

** 19.58683

<br>

### 4.3 Suggested solutions

```{r, warning = F, message = F}
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(visreg))
suppressPackageStartupMessages(library(MASS))

# 1.Read the data
x <- read.csv("data/songsparrow.csv", 
        stringsAsFactors = FALSE)
head(x)

# 2. Year as categorical variable
x$year <- as.character(x$year)

# 3. Plot survival against tarsus length
ggplot(x, aes(tarsus, survival)) +
        geom_jitter(color = "blue", 
                    size = 3, height = 0.04, 
                    width = 0, alpha = 0.5) +
        labs(x = "Tarsus length (mm)", y = "Survival") + 
        theme_classic()

```

<br>


```{r, warning = F, message = F}
# 4. Examine the plot. Can you visualize a trend?

# Same plot, add trend line with geom_smooth()
ggplot(x, aes(tarsus, survival)) +
        geom_jitter(color = "blue", size = 3, 
                    height = 0.04, width = 0, alpha = 0.5) +
        geom_smooth(method = "loess", size = 1, 
                    col = "red", lty = 2, se = FALSE) +
        labs(x = "Tarsus length (mm)", y = "Survival") + 
        theme_classic()

```

<br>


```{r, warning = F, message = F}
# 5. Binomial distribution. Logit link function

# 6. Fit generalized linear model
z <- glm(formula = survival ~ tarsus, 
          family = binomial(link="logit"), 
          data = x)

# 7. Visualize model fit (data points added with points() )
visreg(z, xvar = "tarsus", scale = 'response',
        rug = FALSE, ylim = c(-.1, 1.1))

points(jitter(survival, 0.2) ~ tarsus, data = x, 
        pch = 1, col = "blue", cex = 1, lwd = 1.5)

```

<br>


```{r, warning = F, message = F}

# 8. Estimated regression coefficients of the linear predictor
summary(z)

# 9. Predicted survival probability of a song sparrow having tarsus length 20.5 mm
predict(z, newdata = data.frame(tarsus = 20.5), type = "response")


# 10. LD50
dose.p(z)

# 11. Likelihood-based 95% confidence intervals (logit scale)
confint(z)


# 12. Test null hypothesis of zero slope
anova(z, test = "Chi")

```
<br>

<center>![What is the likelihood of a perfect sunset?](img/lab13-golden.png){width="300"}</center>


## 5 Example: Crab klepto-copulation

<br>

The horseshoe crab, *Limulus polyphemus*, has two alternative male reproductive morphs. Some males attach to females with a special appendage. The females bring these males with them when they crawl onto beaches to dig a nest and lay eggs, which the male then fertilizes. Other males are satellites, which are unattached to females but crowd around nesting pairs and obtain fertilizations. What attributes of a female horseshoe crab determine the number of satellite males she attracts on the beaches?

The data file `satellites.csv` provides measurements of 173 female horseshoe crabs and records the number of satellites they attracted. The data were gathered by Brockman (1996. Satellite male groups in horseshoe crabs, *Limulus polyphemus*. Ethology 102:1-21) and were published by Agresti (2002, Categorical data analysis, 2nd ed. Wiley). The variables are female color, spine condition, carapace width (cm), mass (kg), and number of satellite males.

<br>

### 5.1 Read and examine the data

1. Read the data from the file. View the first few lines of data to make sure it was read correctly. Use the str command to see the variables and groups.

2. Plot the number of satellites against the width of the carapace, a measure of female body size. Fit a smooth curve to examine the trend.

<br>

### 5.2 Fit a generalized linear model

3. Fit a generalized linear model to the relationship between number of satellite males and female carapace width. What type of variable is the number of satellites? What probability distribution might be appropriate to describe the error distribution around a model fit? What is the appropriate link function?

4. Visualize the model fit on the transformed scale, including confidence bands. This plot reminds us that on the transformed scale, `glm()` is fitting a straight line relationship. (Don’t worry about the points – they aren’t the transformed data, but rather are “working values” for the response variable from the last iteration of model fitting, which `glm()` uses behind the scenes to fit the model on the transformed scale.)

5. Visualize the model fit on the original data scale. Note that is it curvilinear.

6. Extract the estimated regression coefficients from your model object. What is the interpretation of these coefficients? On a piece of paper, write down the complete formula for your fitted model.

7. Calculate the likelihood-based 95% confidence interval for the regression coefficients. The most useful estimate is that for the slope: exp(slope) represents the multiple to the response variable accompanying a 1-unit change in the explanatory variable. In other words, if the slope were found to be 1.2, this would indicate that a 1 cm increase in carapace width of a female is accompanied by a 1.2-fold increase in the number of male satellites.

8. Test the null hypothesis of no relationship between number of satellite males and female carapace width. Notice how small the P-value is for the null hypothesis test for the slope. I’m afraid that this is a little optimistic. Why? Read on.

9. When you extracted the regression coefficients from your model object, you probably saw the following line of output: “(Dispersion parameter for poisson family taken to be 1)”. What are we really assuming* here?

10. If you did not want to rely on this assumption (or you wanted to estimate the dispersion parameter), what option is available to you? Refit a generalized linear model without making the assumption that the dispersion parameter is 1.

11. Extract and examine the coefficients of the new glm model object. Examine the estimated dispersion parameter. Is it close to 1? On this basis, which of the two glm fits to the same data would you regard as the more reliable?

12. How do the regression coefficients of this new fit compare with the estimates from the earlier model fit? How do the standard errors compare? Why are they larger** this time?

13. Visualize the new model fit and compare with the plot of the earlier fit. What difference do you notice?

14. Redo the test of significance for the slope of the relationship between number of satellite mates and female carapace width. Remember to use the F test rather than the likelihood ratio test in the anova command. How do the results compare with those from the previous fit?

<br>

### 5.3 Suggested solutions

```{r, warning = F, message = F}
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(visreg))
suppressPackageStartupMessages(library(MASS))

# 1. Read data
x <- read.csv("data/satellites.csv", 
          stringsAsFactors = FALSE)

head(x)

# 2. Plot
ggplot(x, aes(width.cm, nsatellites)) +
        geom_jitter(color = "blue", size = 3, 
                    height = 0.2, width = 0, alpha = 0.5) +
        geom_smooth(method = "loess", size = 1,
                    col = "red", lty = 2, se = FALSE) +
        labs(x = "Carapace width (mm)", y = "No. satellites") + 
        theme_classic()


```

<br>

```{r, warning = F, message = F}
# 3. Fit model to count data, Poisson distribution, log link function
z <- glm(formula = nsatellites ~ width.cm, 
         family = poisson(link = "log"), 
         data = x)

# 4. Visualize model fit (transformed scale)
visreg(z, xvar = "width.cm")
```


<br>

```{r, warning = F, message = F}
# 5. Visualize model fit (original scale), points overlaid
visreg(z, xvar = "width.cm", scale = "response", rug = FALSE)
points(jitter(nsatellites, 0.2) ~ width.cm, data = x, pch = 1, 
        col = "blue", lwd = 1.5)

```


<br>

```{r, warning = F, message = F}
# 6. Estimated regression coefficients
summary(z)


# 7. Likelihood-based 95% confidence interval
confint(z)

# 8. Optimistic test
anova(z, test = "Chi")

# 10. Refit 
z2 <- glm(nsatellites ~ width.cm, family = quasipoisson(link = "log"), data = x)

# 11. Coefficients
summary(z2)



# 13. Visualize
visreg(z2, xvar = "width.cm", scale = "response", rug = FALSE)
points(jitter(nsatellites, 0.2) ~ width.cm, data = x, pch = 1, 
    col = "blue", lwd = 1.5)
```


<br>

```{r, warning = F, message = F}
# 14. Redo test
anova(z2, test = "F")

```
<br>

Comment 1: By using the Poisson distribution to model the residuals, we assume that for any given value of the x-variable, the variance of y is equal to the mean of y. Typically, however, in real data the variance of y is greater than the mean of y at any given x (“overdispersion”). One reason is that a variety of factors cause variation in y, and most aren’t included in the model being fitted.

Comment 2: The model is now taking account of the actual amount of variance in y for each x, which is larger than that assumed by the first model you fitted.

<br>


## 6 Example: Prions -> resistance is not futile (Trekkie reference)

<br>

This last example is to demonstrate the use of `glm()` to model frequencies of different combinations of two (or more) variables in a contingency table. The presence of an interaction between the variables indicates that the relative frequencies of different categories for one variable differ between categories of the other variable. In other words, the two variables are then not independent.

Kuru is a prion disease (similar to Creutzfeldt–Jakob Disease) of the Fore people of highland New Guinea. It was once transmitted by the consumption of deceased relatives at mortuary feasts, a ritual that was ended by about 1960. Using archived tissue samples, Mead et al. (2009, New England Journal of Medicine 361: 2056-2065) investigated genetic variants that might confer resistance to kuru. The data are genotypes at codon 129 of the prion protein gene of young and elderly individuals all having the disease. Since the elderly individuals have survived long exposure to kuru, unusually common genotypes in this group might indicate resistant genotypes. The data are in the file `kurudata.csv`.

<br>

### 6.1 Read and examine the data

1. Read the data from the file. View the first few lines of data to make sure it was read correctly.

2. Create a contingency table comparing the frequency of the three genotypes at codon 129 of the prion protein gene of young and elderly individuals (all having the disease). Notice any pattern? By comparing the frequencies between young people and older people, which genotype is likely to be more resistant to the disease?

3. Create a grouped bar graph illustrating the relative frequencies of the three genotypes between afflicted individuals in the two age categories.

<br>

### 6.2 Fit a generalized linear model

4. To model the frequencies you will first need to convert the contingency table to a “flat” frequency table using data.frame().

5. Fit a generalized linear model to the frequency table. To begin, fit the additive model, i.e., use a model formula without an interaction between the two variables genotype and age.

6. Visualize the fit of the additive model to the frequency data. Notice how the additive model is constrained from fitting the exact frequencies in each category.

7. Repeat the model fitting but include the interaction term as well. Visualize the fit of the model to the data. Notice how this “full” model really is full – it fits the frequencies exactly.

8. Test whether the relative frequencies of the three genotypes differs between the two age groups (i.e., whether there is a significant interaction between age and genotype).

<br>

### 6.3 Suggested solutions

```{r, warning = F, message = F}
# 1. Read the data
x <- read.csv("data/kurudata.csv", 
          stringsAsFactors = FALSE)
head(x)

# 2. Contingency table
x$Cohort <- factor(x$Cohort, levels = c("young","old")) 

kurutable <- table(x)
kurutable

# 3. (Optional) Grouped bar graph 
ggplot(x, aes(x = Cohort, fill = Genotype)) + 
        geom_bar(stat = "count", 
                  position = position_dodge2(preserve="single")) +
        labs(x = "Cohort", y = "Frequency") +
        theme_classic()

```


<br>

```{r, warning = F, message = F}
# 4. Model the frequencies
x1 <- data.frame(kurutable)
x1

# 5. Fit additive model
z <- glm(Freq ~ Genotype + Cohort, family = poisson(link = "log"), data = x1)

# 6. Visualize model fit
# (scale = "response" is broken, visualize on transformed scale instead)
visreg(z, xvar = "Genotype", by = "Cohort")

```

<br>

```{r, warning = F, message = F}
# 7. Fit model with interaction and visualize
# (scale = "response" is broken, visualize on transformed scale instead)
z <- glm(Freq ~ Genotype * Cohort, family = poisson(link = "log"), data = x1)
visreg(z, xvar = "Genotype", by = "Cohort") 

```

<br>

```{r, warning = F, message = F}
# 8. Test interaction
anova(z, test = "Chi")
```


<br><br>

## Harper Adams Data Science

![](img/HDS.png){fig-alt="Harper Data Science" width="125"}

This module is a part of the [MSc in Data Science for Global Agriculture, Food, and Environment](https://www.harper-adams.ac.uk/courses/postgraduate/201194/data-science-for-global-agriculture-food-and-environment "MSc in Data Science") at [Harper Adams University](https://www.harper-adams.ac.uk/ "Harper Adams University"), led by [Ed Harris](https://www.harper-adams.ac.uk/general/staff/profile/201620/Edwin-Harris/ "Ed's Faculty page").
